---
layout: post
title: "Privacy, Internet & Filter Bubbles: When Technology Backfires."
date: 2021-07-05
author: "Lakshy Sharma"
---

<div style="text-align: center"><img align="center" width="426" height="240" src="/The-Thought-Archive/assets/media/Filter-bubbles.jpg"></div>
<br><br>
The world is changing.
The term 'cyberspace' now includes our physical world. But what we often miss is how the elements of cyberspace that we thought were confined behind the wall of internet are starting to influence our brains, how the elements of cyberspace are starting to change how we think and interact with the physical world. 

In the era where people are willing to give away their privacies for a comfort of few clicks I will try to answer some important questions.
1. How exposed are we on internet?
2. How is Big Tech using our data and why should you care?
3. How much comfort is too much?
<!--display-->

## The Internet and Privacy.

How do you feel when someone over the street looks in your home with binoculars?
If the answer is uncomfortable, congratulations! You understand the concept of privacy.

The internet has brought us together, but it has also amplified our need to express ourselves. We all like to share our achievements, happiness, and thoughts on things we care about with our loved ones. Each one of us has a group of people we trust and know will understand our perspective and not use our words against us. But what will happen if someone you don't trust starts listening to these conversations? 

When you sign up for any online messaging service to talk with people you trust, you are essentially inserting a middleman (the host of the service) and trusting them not to listen in on the conversation. So if the middleman has all your data, how can you hold them accountable if they start making bad use of it? The privacy policy you just ignored and signed before using the service is your only tool against these service providers, and if you did not check it before signing up, you don't have much control.

Therefore, it is essential to read the terms of service and privacy policy of any service you use. One great, free tool to help with this is <a href= "https://tosdr.org/">https://tosdr.org/</a>. Just input the name of the service, and you can get an overview of their terms of service and privacy policy.

## What is Metadata and how do companies use it?

Now, as we understand why privacy policies are important, let's delve into another term often found in these policies: metadata.

Many companies offering you online messaging services argue that messages you send are protected because they are end-to-end encrypted and only data they can track is the metadata, which according to them is 'harmless'. Some questions I would like to answer in this section are :
- What is metadata?
- Is collection of metadata really harmless?
- Is the usage of your metadata to make money ethical?

### What is Metadata?

Metadata is data about the data. Meaning it contains information like:
1. Who is talking to whom? (Identity of people who are conversing)
2. Where are both the parties talking from? (GPS)
3. What software talking parties are using other than the messaging apps?(For example, what OS you are running and other apps)
4. What is the average length of messages?
5. Time and duration of a conversation.
6. Duration of your calls. (For calling services)

What it does not contain:
1. The actual contents of your message.

### Is metadata really harmless?

Metadata may seem harmless, but is it really? If someone cannot read the actual contents, does that mean it is harmless? Let's consider another case.

Imagine you are talking to people and the middleman cannot read the contents of the messages, but they know who you talked to and for how long. At first, this seems okay. However, the middleman may start selling this information to other people and make money from your metadata.

You may wonder why anyone would pay for metadata. The truth is, just because something is harmless does not mean it is worthless. Metadata can be a goldmine for advertisers. Information such as your location, call duration, and software usage can reveal a lot about you, making it easier for advertisers to target you with ads. Therefore, advertisers pay the middleman for the metadata they collect.

It is important to note that metadata is not always harmless. Simple Google searches can reveal many instances where the FBI has used metadata to track down criminals. If the FBI can use metadata for legitimate purposes, then a person with malicious intent can use it for bad purposes as well. It is always wise to find out what a company considers to be metadata and how they use it. You can find this information in their privacy policy.

Overall, the discussion of advertisements in software is a complex topic with many different perspectives. Therefore, it deserves its own post, and I will not delve further into it here.

### Is it Ethical to Use Metadata for Profit?

**Before we begin**: I don't believe it's anyone's place to tell you how your data should be treated. It's always up to you to determine the value of your data. This section simply reflects my personal views, and you're free to disagree.
To discuss ethics of metadata processing we must understand how it is done.

To discuss the ethics of metadata processing, we must first understand how it's collected. Metadata is typically gathered through one or more of the following methods:

1. App usage data
2. Browser cookies and trackers from websites you visit
3. Data collected by mobile apps based on permissions you've granted.
4. Data collected by your mobile phone's operating system, unless you've opted out.
5. Social media behavior, such as your friend list and interactions.
6. Data from your cloud storage and email accounts.
7. Other methods I may be unaware of.

Once collected, the metadata is processed to create groups of "similar people" and the data is then sold to organizations for use in targeted advertising.

But where do ethics come into play?

One argument in favor of using metadata for profit is that it can be considered payment for the services you've used. However, I believe this is only ethical if the user is fully aware of what data is being collected and how it's being used. If a service is advertised as "free," then selling user data cannot be considered a fair payment.

One argument in favor of using metadata for profit is that it can be considered payment for the services you've used. However, I believe this is only ethical if the user is fully aware of what data is being collected and how it's being used. If a service is advertised as "free," then selling user data cannot be considered a fair payment.

In short, if there's a legitimate use for data, there's also an illegitimate use, and companies that sell user data have a responsibility to inform their customers about how their data will be used.

You may wonder how targeted marketing can lead to mass manipulation. The answer is filter bubbles.

## Filter Bubbles
Filter bubbles refer to a situation where people only consume information and ideas that align with their preexisting beliefs, while ignoring alternative perspectives. This has always been a natural aspect of human behavior, as people tend to form social connections with those who share similar values and interests. However, the rise of personalized content algorithms has turned this innocent behavior into a big problem in recent years.

The consequences of filter bubbles can be serious, including polarization, intolerance, and even violence. It is crucial to actively seek out diverse perspectives to broaden our understanding of the world and avoid consuming content that reinforces our existing beliefs.

Although filter bubbles are to some extent natural, excessive use of content tailoring technology like artificial intelligence and machine learning algorithms can create echo chambers that lead to mass manipulation. Many companies offer tailored content as a personalized service, but uncontrolled personalization can lead to the formation of filter bubbles, which can be exploited by ad companies and political campaigns.

To address the negative effects of filter bubbles, users must actively seek out different perspectives and make efforts to avoid division. Additionally, it is crucial to have an understanding of how machine learning algorithms work, including the two primary methods used to develop recommendation algorithms: user history-based filtering and collaborative filtering.

User history-based filtering depends on a user's past behavior and activity on a website or platform to provide recommendations. For example, if a user frequently clicks on articles related to politics, the algorithm will suggest more political content. This method can be effective in personalizing content for users with established interests and preferences, but it may limit exposure to new topics and viewpoints.

Collaborative filtering, on the other hand, analyzes the preferences and behavior of multiple users to make recommendations. The algorithm identifies users with similar interests and preferences and recommends content that they have consumed. This method can help users discover new topics and perspectives outside of their established interests, but it may also lead to the "echo chamber" effect where users are only recommended content that aligns with their existing beliefs and biases.

## The Harmful Effects of Personalized Content

Let's imagine a hypothetical situation:

1. You visit a grocery store and purchase carrots.
2. The store notices that you frequently buy carrots and starts showing you ads for carrots everywhere you go.
3. Eventually, the store sells your data to other retailers, who also begin displaying carrot ads to you.
4. Later, the store sells your data to a social media company, which starts recommending carrot-themed groups to you.
5. If that doesn't creep you out enough, let's say you decide to join a carrot enthusiast group. There, you notice that everyone is bashing eggplants, and the social media app picks up on your dislike of eggplants. It begins recommending articles that praise carrots and disparage eggplants.
  - *This is where you should read up on <a href="https://en.wikipedia.org/wiki/Echo_chamber_%28media%29">echo chambers</a>*
6. Soon enough, you develop a strong aversion to eggplants and begin to think that those who enjoy them are irrational or strange.

While this hypothetical scenario involves something as harmless as carrots and eggplants, it's not difficult to imagine similar situations in the realm of politics. Personalized content can easily become a powerful tool to silence opposing views and reinforce biases. The lack of exposure to diverse perspectives can have a profound impact on our minds, causing us to become intolerant of opposing views and disregarding them altogether.

The real danger of personalized content is that it operates silently, without our knowledge or consent. Filter bubbles are the ultimate weapons in today's digital world, where people are willing to trade privacy for convenience. Such bubbles can be easily manipulated to feed us a particular narrative and create a false sense of reality. They can be used to brainwash people, influence election results, and sway public opinion. Individuals who are susceptible to over-attachment to a particular organization or group can be easily influenced, making them believe that their beliefs and values are under threat from external forces.

In short, what was once meant to enhance our online experiences by showing us content tailored to our interests can easily turn into a dangerous weapon, used to control and manipulate our opinions and actions.

## How do we protect our privacy and avoid manipulation?

It's not practical to suggest we go back to a time before technology existed. Instead, we need to take action to protect our privacy and avoid being manipulated.

What can governments and lawmakers do?

1. Increase awareness about privacy in cyberspace and make it mandatory for companies to disclose what data is being collected, how it will be used, and who else will have access to it. Companies should also be required to name the organizations hiding behind the "third party" labels in their privacy policies.
2. Limit the use of artificial intelligence to combat filter bubbles and establish rules on how much content filtering is allowed.
3. Encourage people to read opposing opinions and ensure social media companies don't engage in prolonged targeting of users for ads.

What can we do as individuals?

1. Avoid liking every article you read and only like exceptional content that presents multiple perspectives.
2. Use ad-blockers whenever possible.
3. Make an effort to understand the other side of the coin and read different types of opinions.
4. Read privacy policies before signing up for internet-based services.

Let's use technology wisely and prevent it from using us.

*Alvida*

Note: If you believe you have found a technical mistake in my blog post, please contact me via email.
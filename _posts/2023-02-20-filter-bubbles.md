---
layout: post
title: "How Filter Bubbles Shape Our Worldview: Understanding the Role of Algorithms in Online Content"
date: 2021-07-05
author: "Lakshy Sharma"
---

<div style="text-align: center"><img align="center" width="426" height="240" src="/The-Thought-Archive/assets/media/Filter-bubbles.jpg"></div>
<br><br>
The world is undergoing a transformation, and the lines between cyberspace and the physical world are blurring. What many of us fail to realize is how the elements of cyberspace, once thought to be confined behind the walls of the internet, are beginning to impact our thoughts and actions in the physical world.

In an era where people willingly trade privacy for a few clicks of convenience, it's crucial to ask some critical questions. 
1. How much of our personal information is exposed online? 
2. How are big tech companies using our data, and what are the implications? 
3. When does the pursuit of comfort cross the line into the realm of overindulgence?

Through this post I intend to show you how technology is subtly impacting our daily decisions and what can we do to reduce this influence.
<!--display-->

## Privacy in the Age of Internet

Imagine someone peering into your home with binoculars from the street. Most of us would feel uncomfortable with that, and rightfully so. It's an invasion of our privacy.

The internet has brought us closer together, but it has also increased our need to express ourselves. We love to share our accomplishments, happiness, and opinions with our trusted friends and family. But what happens when someone we don't trust starts listening in on these conversations?

When you sign up for an online messaging service to talk with your loved ones, you are essentially introducing a middleman – the host of the service – and trusting them not to eavesdrop on your conversations. If the middleman has access to all your data, what happens if they misuse it? Unfortunately, most of us don't take the time to read the privacy policy or terms of service before using these services, leaving us vulnerable to potential abuses.

To protect ourselves, it's crucial to read the terms of service and privacy policy of any service we use. Fortunately, there are free tools like <a href= "https://tosdr.org/">tosdr</a> that can help with this. By simply inputting the name of the service, you can get an overview of their terms of service and privacy policy. Don't leave your privacy up to chance – take control and protect yourself online.

## What is Metadata and how do companies use it?

Now, as we understand why privacy policies are important, let's delve into another term often found in these policies: metadata.

Many companies offering you online messaging services argue that messages you send are protected because they are end-to-end encrypted and only data they can track is the metadata, which according to them is 'harmless'. Some questions I would like to answer in this section are :
- What is metadata?
- Is collection of metadata really harmless?
- Is the usage of your metadata to make money ethical?

### What is Metadata?

Metadata is data about the data. Meaning it contains information like:
1. Who is talking to whom? (Identity of people who are conversing)
2. Where are both the parties talking from? (GPS)
3. What software talking parties are using other than the messaging apps?(For example, what OS you are running and other apps)
4. What is the average length of messages?
5. Time and duration of a conversation.
6. Duration of your calls. (For calling services)

What it does not contain:
1. The actual contents of your message.

### Is metadata really harmless?

Metadata may seem harmless, but is it really? If someone cannot read the actual contents, does that mean it is harmless? Let's consider another case.

Imagine you are talking to people and the middleman cannot read the contents of the messages, but they know who you talked to and for how long. At first, this seems okay. However, the middleman may start selling this information to other people and make money from your metadata.

You may wonder why anyone would pay for metadata. The truth is, just because something is harmless does not mean it is worthless. Metadata can be a goldmine for advertisers. Information such as your location, call duration, and software usage can reveal a lot about you, making it easier for advertisers to target you with ads. Therefore, advertisers pay the middleman for the metadata they collect.

It is important to note that metadata is not always harmless. Simple Google searches can reveal many instances where the FBI has used metadata to track down criminals. If the FBI can use metadata for legitimate purposes, then a person with malicious intent can use it for bad purposes as well. It is always wise to find out what a company considers to be metadata and how they use it. You can find this information in their privacy policy.

Meanwhile lets have a look at the ethics of metadata processing.

### Is it Ethical to Use Metadata for Profit?

**Before we begin**: I don't believe it's anyone's place to tell you how your data should be treated. It's always up to you to determine the value of your data. This section simply reflects my personal views, and you're free to disagree.

To discuss the ethics of metadata processing, we must first understand how it's collected. Metadata is typically gathered through one or more of the following methods:

1. App usage data
2. Browser cookies and trackers from websites you visit
3. Data collected by mobile apps based on permissions you've granted.
4. Data collected by your mobile phone's operating system, unless you've opted out.
5. Social media behavior, such as your friend list and interactions.
6. Data from your cloud storage and email accounts.
7. Other methods I may be unaware of.

Once collected, the metadata is processed to create groups of "similar people" and the data is then sold to organizations for use in targeted advertising.

But where do ethics come into play?

One argument in favor of using metadata for profit is that it can be considered payment for the services you've used. However, I believe this is only ethical if the user is fully aware of what data is being collected and how it's being used. If a service is advertised as "free," then selling user data cannot be considered a fair payment.

In short, if there's a legitimate use for data, there's also an illegitimate use, and companies that sell user data have a responsibility to inform their customers about how their data will be used.

You may wonder how targeted marketing can lead to mass manipulation. The answer is filter bubbles.

## Filter Bubbles
Filter bubbles refer to a situation where people only consume information and ideas that align with their preexisting beliefs, while ignoring alternative perspectives. This has always been a natural aspect of human behavior, as people tend to form social connections with those who share similar values and interests. However, the rise of personalized content algorithms has turned this innocent behavior into a big problem in recent years.

The consequences of filter bubbles can be serious, including polarization, intolerance, and even violence. It is crucial to actively seek out diverse perspectives to broaden our understanding of the world and avoid consuming content that reinforces our existing beliefs.

Although filter bubbles are to some extent natural, excessive use of content tailoring technology like artificial intelligence and machine learning algorithms can create echo chambers that lead to mass manipulation. Many companies offer tailored content as a personalized service, but uncontrolled personalization can lead to the formation of filter bubbles, which can be exploited by ad companies and political campaigns.

To address the negative effects of filter bubbles, users must actively seek out different perspectives and make efforts to avoid division. Additionally, it is crucial to have an understanding of how machine learning algorithms work, including the two primary methods used to develop recommendation algorithms: user history-based filtering and collaborative filtering.

User history-based filtering depends on a user's past behavior and activity on a website or platform to provide recommendations. For example, if a user frequently clicks on articles related to politics, the algorithm will suggest more political content. This method can be effective in personalizing content for users with established interests and preferences, but it may limit exposure to new topics and viewpoints.

Collaborative filtering, on the other hand, analyzes the preferences and behavior of multiple users to make recommendations. The algorithm identifies users with similar interests and preferences and recommends content that they have consumed. This method can help users discover new topics and perspectives outside of their established interests, but it may also lead to the "echo chamber" effect where users are only recommended content that aligns with their existing beliefs and biases.

## The Harmful Effects of Personalized Content

Let's imagine a hypothetical situation:

1. You visit a grocery store and purchase carrots.
2. The store notices that you frequently buy carrots and starts showing you ads for carrots everywhere you go.
3. Eventually, the store sells your data to other retailers, who also begin displaying carrot ads to you.
4. Later, the store sells your data to a social media company, which starts recommending carrot-themed groups to you.
5. If that doesn't creep you out enough, let's say you decide to join a carrot enthusiast group. There, you notice that everyone is bashing eggplants, and the social media app picks up on your dislike of eggplants. It begins recommending articles that praise carrots and disparage eggplants.
  - *This is where you should read up on <a href="https://en.wikipedia.org/wiki/Echo_chamber_%28media%29">echo chambers</a>*
6. Soon enough, you develop a strong aversion to eggplants and begin to think that those who enjoy them are irrational or strange.

While this hypothetical scenario involves something as harmless as carrots and eggplants, it's not difficult to imagine similar situations in the realm of politics. Personalized content can easily become a powerful tool to silence opposing views and reinforce biases. The lack of exposure to diverse perspectives can have a profound impact on our minds, causing us to become intolerant of opposing views and disregarding them altogether.

The real danger of personalized content is that it operates silently, without our knowledge or consent. Filter bubbles are the ultimate weapons in today's digital world, where people are willing to trade privacy for convenience. Such bubbles can be easily manipulated to feed us a particular narrative and create a false sense of reality. They can be used to brainwash people, influence election results, and sway public opinion. Individuals who are susceptible to over-attachment to a particular organization or group can be easily influenced, making them believe that their beliefs and values are under threat from external forces.

In short, what was once meant to enhance our online experiences by showing us content tailored to our interests can easily turn into a dangerous weapon, used to control and manipulate our opinions and actions.

## How do we protect our privacy and avoid manipulation?

It's not practical to suggest we go back to a time before technology existed. Instead, we need to take action to protect our privacy and avoid being manipulated.

What can governments and lawmakers do?

1. Increase awareness about privacy in cyberspace and make it mandatory for companies to disclose what data is being collected, how it will be used, and who else will have access to it. Companies should also be required to name the organizations hiding behind the "third party" labels in their privacy policies.
2. Limit the use of artificial intelligence to combat filter bubbles and establish rules on how much content filtering is allowed.
3. Encourage people to read opposing opinions and ensure social media companies don't engage in prolonged targeting of users for ads.

What can we do as individuals?

1. Avoid liking every article you read and only like exceptional content that presents multiple perspectives.
2. Use ad-blockers whenever possible.
3. Make an effort to understand the other side of the coin and read different types of opinions.
4. Read privacy policies before signing up for internet-based services.

Let's use technology wisely and prevent it from using us.

*Thank You*

Note: If you believe you have found a technical mistake in my blog post, please contact me via email.

## References

1. (**Ensuring that you do not fall prey to an echo chamber, have a look at the opposing argument**) Dubois, Elizabeth and Grant Blank. “The echo chamber is overstated: the moderating effect of political interest and diverse media.” Information, Communication & Society 21 (2018): 729 - 745.
2. Pariser, Eli. “The Filter Bubble: What the Internet Is Hiding from You.” (2011).
3. Flaxman, Seth, Sharad Goel and Justin M. Rao. “Filter Bubbles, Echo Chambers, and Online News Consumption.” PSN: Political Communication (Topic) (2016): n. pag.